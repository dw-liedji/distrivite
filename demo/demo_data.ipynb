{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42cbd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import django\n",
    "\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"quanta.settings\")\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "434c1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.users.models import User\n",
    "\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c560f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from django.db import transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f5a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/data_migration.py (continued)\n",
    "from decimal import Decimal\n",
    "from django.utils import timezone\n",
    "from phonenumber_field.phonenumber import PhoneNumber\n",
    "from apps.orders.models import (\n",
    "    Customer, Category, Item, Supplier, Batch, Stock,\n",
    "    Facturation, FacturationStock, Transaction,\n",
    "    FacturationPayment, Organization, OrganizationUser as NewOrganizationUser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adeb6101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new organization: Agri distribution\n"
     ]
    }
   ],
   "source": [
    "# Create an organization with get_or_create\n",
    "organization, created = Organization.objects.get_or_create(\n",
    "    name=\"Agri distribution\",\n",
    "    defaults={\n",
    "        'slug': 'main-hospital',\n",
    "        'contact_email': 'contact@mainhospital.com',\n",
    "        'credential': 'HOSP12345',\n",
    "        'code': 'MH001',\n",
    "        'sub_name': 'Main Branch',\n",
    "        'country': 'Cameroon',\n",
    "        'city': 'Douala',\n",
    "        'street_address': '123 Main Street',\n",
    "        'contact_number': '+237672120240',\n",
    "        'short_name': 'MH',\n",
    "        'tax_rate': Decimal('18.50'),\n",
    "        'is_online': True,\n",
    "        'timezone': 'Africa/Douala',\n",
    "        'contribuable': '123456789',\n",
    "        'created': timezone.now(),\n",
    "        'modified': timezone.now(),\n",
    "    }\n",
    ")\n",
    "\n",
    "if created:\n",
    "    print(f\"Created new organization: {organization.name}\")\n",
    "else:\n",
    "    print(f\"Organization already exists: {organization.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1863f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "organization_id=\"69393ba2-3fbd-4ca8-a2d8-2e75ff14093d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c9c761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Organization.objects.filter(id=organization.id).update(id=organization_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492b1c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8344b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def import_organization_data(export_dir='./demo/data', target_org_id=None):\n",
    "    \"\"\"\n",
    "    Import data from CSV files to new models for a specific organization.\n",
    "    \n",
    "    Args:\n",
    "        export_dir: Directory containing CSV files\n",
    "        target_org_id: ID of the organization to import data for (required)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (success: bool, message: str)\n",
    "    \"\"\"\n",
    "    if not target_org_id:\n",
    "        return False, \"Error: target_org_id is required\"\n",
    "    \n",
    "    try:\n",
    "        with transaction.atomic():\n",
    "            print(f\"Starting data import for organization ID: {target_org_id}...\")\n",
    "            \n",
    "           \n",
    "            org_map = {target_org_id: target_org_id}\n",
    "            \n",
    "            # Import in correct order to maintain foreign key relationships\n",
    "            user_map = _import_users(export_dir)\n",
    "            ou_map = _import_organization_users(export_dir, org_map, user_map, target_org_id)\n",
    "            customer_map = _import_customers(export_dir, org_map, target_org_id)\n",
    "            supplier_map = _import_suppliers(export_dir, org_map, target_org_id)\n",
    "            category_map = _import_categories(export_dir, org_map, target_org_id)\n",
    "            item_map = _import_items(export_dir, org_map, category_map, target_org_id)\n",
    "            batch_map = _import_batches(export_dir, org_map, item_map, supplier_map, ou_map, target_org_id)\n",
    "            \n",
    "            # Import facturations first\n",
    "            facturation_map = _import_facturations(export_dir, org_map, customer_map, ou_map, target_org_id)\n",
    "            \n",
    "            # Now create Stock records from FacturationBatch data\n",
    "            stock_map = _create_stocks_from_facturation_batches(\n",
    "                export_dir, org_map, batch_map, ou_map, target_org_id\n",
    "            )\n",
    "            \n",
    "            # Import FacturationStock\n",
    "            _import_facturation_stocks(export_dir, org_map, stock_map, facturation_map, ou_map, target_org_id)\n",
    "            \n",
    "            # Import remaining models\n",
    "            _import_transactions(export_dir, org_map, ou_map, target_org_id)\n",
    "            _import_facturation_payments(export_dir, org_map, facturation_map, ou_map, target_org_id)\n",
    "            \n",
    "        return True, f'Data import completed successfully for organization ID: {target_org_id}!'\n",
    "        \n",
    "    except Exception as e:\n",
    "        return False, f\"Import failed: {str(e)}\"\n",
    "def _import_users(export_dir):\n",
    "    \"\"\"Import users from export\"\"\"\n",
    "    filepath = os.path.join(export_dir, 'users.csv')\n",
    "    user_map = {}\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: Users file not found: {filepath}\")\n",
    "        return user_map\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        users_to_create = []\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                # Check if user already exists by email\n",
    "                existing_user = User.objects.filter(email=row['email']).first()\n",
    "                if existing_user:\n",
    "                    user_map[str(row['id'])] = existing_user\n",
    "                    continue\n",
    "                \n",
    "                # Create user\n",
    "                user = User(\n",
    "                    id=str(row['id']),\n",
    "                    email=row['email'] or f\"user{row['id']}@example.com\",\n",
    "                    username=row['username'] or f\"user{row['id']}\",\n",
    "                    is_patient=row['is_patient'].lower() == 'true' if row.get('is_patient') else True,\n",
    "                    is_staff=row['is_staff'].lower() == 'true' if row.get('is_staff') else False,\n",
    "                    is_active=row['is_active'].lower() == 'true' if row.get('is_active') else True,\n",
    "                    is_superuser=row['is_superuser'].lower() == 'true' if row.get('is_superuser') else False,\n",
    "                    date_joined=_parse_datetime(row.get('date_joined')),\n",
    "                    last_login=_parse_datetime(row.get('last_login')),\n",
    "                )\n",
    "                \n",
    "                # Handle phone number\n",
    "                if row.get('phone_number'):\n",
    "                    try:\n",
    "                        user.phone_number = PhoneNumber.from_string(row['phone_number'])\n",
    "                    except:\n",
    "                        user.phone_number = None\n",
    "                \n",
    "                users_to_create.append(user)\n",
    "                user_map[str(row['id'])] = user\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error importing user {row.get('id')}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if users_to_create:\n",
    "            # Set default password for all users\n",
    "            for user in users_to_create:\n",
    "                if not user.has_usable_password():\n",
    "                    user.set_password('DataViteAI')\n",
    "            \n",
    "            User.objects.bulk_create(users_to_create)\n",
    "            print(f\"Imported {len(users_to_create)} users\")\n",
    "    \n",
    "    return user_map\n",
    "\n",
    "def _import_organization_users(export_dir, org_map, user_map, target_org_id):\n",
    "    \"\"\"Import organization users for target organization\"\"\"\n",
    "    filepath = os.path.join(export_dir, 'organization_users.csv')\n",
    "    ou_map = {}\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: Organization users file not found: {filepath}\")\n",
    "        return ou_map\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        ous_to_create = []\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                org_id = str(row['organization_id'])\n",
    "                user_id = str(row['user_id'])\n",
    "                \n",
    "                # Only import for target organization\n",
    "                if org_id != target_org_id:\n",
    "                    continue\n",
    "                \n",
    "                if org_id not in org_map or user_id not in user_map:\n",
    "                    print(f\"Skipping organization user {row['id']}: org={org_id}, user={user_id}\")\n",
    "                    continue\n",
    "                \n",
    "                # Check if already exists\n",
    "                existing_ou = NewOrganizationUser.objects.filter(\n",
    "                    organization_id=org_map[org_id],\n",
    "                    user=user_map[user_id],\n",
    "                    is_active=True,\n",
    "                    can_edit_price=True,\n",
    "                    can_print_transaction=True,\n",
    "                    can_print_bill=True,\n",
    "                ).first()\n",
    "                \n",
    "                if existing_ou:\n",
    "                    ou_map[str(row['id'])] = existing_ou\n",
    "                    continue\n",
    "                \n",
    "                ou = NewOrganizationUser(\n",
    "                    id=str(row['id']),\n",
    "                    organization_id=org_map[org_id],\n",
    "                    user=user_map[user_id],\n",
    "                    created=_parse_datetime(row.get('created')),\n",
    "                    modified=_parse_datetime(row.get('modified'))\n",
    "                )\n",
    "                ous_to_create.append(ou)\n",
    "                ou_map[str(row['id'])] = ou\n",
    "            except Exception as e:\n",
    "                print(f\"Error importing organization user {row.get('id')}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if ous_to_create:\n",
    "            NewOrganizationUser.objects.bulk_create(ous_to_create)\n",
    "            print(f\"Imported {len(ous_to_create)} organization users\")\n",
    "    \n",
    "    return ou_map\n",
    "\n",
    "def _import_customers(export_dir, org_map, target_org_id):\n",
    "    \"\"\"Import customers for target organization\"\"\"\n",
    "    filepath = os.path.join(export_dir, 'customers.csv')\n",
    "    customer_map = {}\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: Customers file not found: {filepath}\")\n",
    "        return customer_map\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        customers_to_create = []\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                org_id = str(row['organization_id'])\n",
    "                \n",
    "                # Only import for target organization\n",
    "                if org_id != target_org_id:\n",
    "                    continue\n",
    "                \n",
    "                if org_id not in org_map:\n",
    "                    print(f\"Skipping customer {row['id']}: org {org_id} not found\")\n",
    "                    continue\n",
    "                \n",
    "                customer = Customer(\n",
    "                    id=str(row['id']),\n",
    "                    organization_id=org_map[org_id],\n",
    "                    name=row['name'],\n",
    "                    phone_number=row['phone_number'] or None,\n",
    "                    created=_parse_datetime(row.get('created')),\n",
    "                    modified=_parse_datetime(row.get('modified'))\n",
    "                )\n",
    "                customers_to_create.append(customer)\n",
    "                customer_map[str(row['id'])] = customer\n",
    "            except Exception as e:\n",
    "                print(f\"Error importing customer {row.get('id')}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if customers_to_create:\n",
    "            Customer.objects.bulk_create(customers_to_create)\n",
    "            print(f\"Imported {len(customers_to_create)} customers\")\n",
    "    \n",
    "    return customer_map\n",
    "\n",
    "def _import_suppliers(export_dir, org_map, target_org_id):\n",
    "    \"\"\"Import suppliers for target organization\"\"\"\n",
    "    filepath = os.path.join(export_dir, 'suppliers.csv')\n",
    "    supplier_map = {}\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: Suppliers file not found: {filepath}\")\n",
    "        return supplier_map\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        suppliers_to_create = []\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                org_id = str(row['organization_id'])\n",
    "                \n",
    "                # Only import for target organization\n",
    "                if org_id != target_org_id:\n",
    "                    continue\n",
    "                \n",
    "                if org_id not in org_map:\n",
    "                    print(f\"Skipping supplier {row['id']}: org {org_id} not found\")\n",
    "                    continue\n",
    "                \n",
    "                supplier = Supplier(\n",
    "                    id=str(row['id']),\n",
    "                    organization_id=org_map[org_id],\n",
    "                    name=row['name'],\n",
    "                    is_active=row['is_active'].lower() == 'true' if row['is_active'] else True,\n",
    "                    created=_parse_datetime(row.get('created')),\n",
    "                    modified=_parse_datetime(row.get('modified'))\n",
    "                )\n",
    "                suppliers_to_create.append(supplier)\n",
    "                supplier_map[str(row['id'])] = supplier\n",
    "            except Exception as e:\n",
    "                print(f\"Error importing supplier {row.get('id')}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if suppliers_to_create:\n",
    "            Supplier.objects.bulk_create(suppliers_to_create)\n",
    "            print(f\"Imported {len(suppliers_to_create)} suppliers\")\n",
    "    \n",
    "    return supplier_map\n",
    "\n",
    "def _import_categories(export_dir, org_map, target_org_id):\n",
    "    \"\"\"Import categories for target organization\"\"\"\n",
    "    filepath = os.path.join(export_dir, 'categories.csv')\n",
    "    category_map = {}\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: Categories file not found: {filepath}\")\n",
    "        return category_map\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        categories_to_create = []\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                org_id = str(row['organization_id'])\n",
    "                \n",
    "                # Only import for target organization\n",
    "                if org_id != target_org_id:\n",
    "                    continue\n",
    "                \n",
    "                if org_id not in org_map:\n",
    "                    print(f\"Skipping category {row['id']}: org {org_id} not found\")\n",
    "                    continue\n",
    "                \n",
    "                category = Category(\n",
    "                    id=str(row['id']),\n",
    "                    organization_id=org_map[org_id],\n",
    "                    name=row['name'],\n",
    "                    is_active=row['is_active'].lower() == 'true' if row.get('is_active') else True,\n",
    "                    created=_parse_datetime(row.get('created')),\n",
    "                    modified=_parse_datetime(row.get('modified'))\n",
    "                )\n",
    "                categories_to_create.append(category)\n",
    "                category_map[str(row['id'])] = category\n",
    "            except Exception as e:\n",
    "                print(f\"Error importing category {row.get('id')}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if categories_to_create:\n",
    "            Category.objects.bulk_create(categories_to_create)\n",
    "            print(f\"Imported {len(categories_to_create)} categories\")\n",
    "    \n",
    "    return category_map\n",
    "\n",
    "def _import_items(export_dir, org_map, category_map, target_org_id):\n",
    "    \"\"\"Import items for target organization\"\"\"\n",
    "    filepath = os.path.join(export_dir, 'items.csv')\n",
    "    item_map = {}\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: Items file not found: {filepath}\")\n",
    "        return item_map\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        items_to_create = []\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                org_id = str(row['organization_id'])\n",
    "                category_id = str(row['category_id'])\n",
    "                \n",
    "                # Only import for target organization\n",
    "                if org_id != target_org_id:\n",
    "                    continue\n",
    "                \n",
    "                if org_id not in org_map or category_id not in category_map:\n",
    "                    print(f\"Skipping item {row['id']}: org={org_id}, category={category_id}\")\n",
    "                    continue\n",
    "                \n",
    "                item = Item(\n",
    "                    id=str(row['id']),\n",
    "                    organization_id=org_map[org_id],\n",
    "                    category=category_map[category_id],\n",
    "                    name=row['name'],\n",
    "                    alert_quantity=int(row['alert_quantity']) if row['alert_quantity'] else 1,\n",
    "                    is_active=row['is_active'].lower() == 'true' if row.get('is_active') else True,\n",
    "                    created=_parse_datetime(row.get('created')),\n",
    "                    modified=_parse_datetime(row.get('modified'))\n",
    "                )\n",
    "                items_to_create.append(item)\n",
    "                item_map[str(row['id'])] = item\n",
    "            except Exception as e:\n",
    "                print(f\"Error importing item {row.get('id')}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if items_to_create:\n",
    "            Item.objects.bulk_create(items_to_create)\n",
    "            print(f\"Imported {len(items_to_create)} items\")\n",
    "    \n",
    "    return item_map\n",
    "\n",
    "def _import_batches(export_dir, org_map, item_map, supplier_map, ou_map, target_org_id):\n",
    "    \"\"\"Import batches for target organization\"\"\"\n",
    "    filepath = os.path.join(export_dir, 'batches.csv')\n",
    "    batch_map = {}\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: Batches file not found: {filepath}\")\n",
    "        return batch_map\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        batches_to_create = []\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                org_id = str(row['organization_id'])\n",
    "                item_id = str(row['item_id'])\n",
    "                supplier_id = str(row['supplier_id'])\n",
    "                last_maintainer_id = str(row['last_maintainer_id'])\n",
    "                \n",
    "                # Only import for target organization\n",
    "                if org_id != target_org_id:\n",
    "                    continue\n",
    "                \n",
    "                if (org_id not in org_map or item_id not in item_map or \n",
    "                    supplier_id not in supplier_map or last_maintainer_id not in ou_map):\n",
    "                    print(f\"Skipping batch {row['id']}: missing foreign keys\")\n",
    "                    continue\n",
    "                \n",
    "                batch = Batch(\n",
    "                    id=str(row['id']),\n",
    "                    organization_id=org_map[org_id],\n",
    "                    item=item_map[item_id],\n",
    "                    batch_number=row['batch_number'] or f\"BATCH-{row['id']}\",\n",
    "                    supplier=supplier_map[supplier_id],\n",
    "                    received_date=_parse_date(row['received_date']),\n",
    "                    expiration_date=_parse_date(row['expiration_date']),\n",
    "                    purchase_price=Decimal(row['purchase_price']) if row['purchase_price'] else Decimal('0'),\n",
    "                    facturation_price=Decimal(row['facturation_price']) if row['facturation_price'] else Decimal('0'),\n",
    "                    quantity=int(float(row['quantity'])) if row['quantity'] else 0,\n",
    "                    last_checked=_parse_datetime(row.get('last_checked')),\n",
    "                    last_maintainer=ou_map[last_maintainer_id],\n",
    "                    is_active=row['is_active'].lower() == 'true' if row.get('is_active') else True,\n",
    "                    created=_parse_datetime(row.get('created')),\n",
    "                    modified=_parse_datetime(row.get('modified'))\n",
    "                )\n",
    "                batches_to_create.append(batch)\n",
    "                batch_map[str(row['id'])] = batch\n",
    "            except Exception as e:\n",
    "                print(f\"Error importing batch {row.get('id')}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if batches_to_create:\n",
    "            Batch.objects.bulk_create(batches_to_create)\n",
    "            print(f\"Imported {len(batches_to_create)} batches\")\n",
    "    \n",
    "    return batch_map\n",
    "\n",
    "def _import_facturations(export_dir, org_map, customer_map, ou_map, target_org_id):\n",
    "    \"\"\"Import facturations for target organization\"\"\"\n",
    "    filepath = os.path.join(export_dir, 'facturations.csv')\n",
    "    facturation_map = {}\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: Facturations file not found: {filepath}\")\n",
    "        return facturation_map\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        facturations_to_create = []\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                org_id = str(row['organization_id'])\n",
    "                customer_id = str(row['customer_id'])\n",
    "                org_user_id = str(row['organization_user_id'])\n",
    "                \n",
    "                # Only import for target organization\n",
    "                if org_id != target_org_id:\n",
    "                    continue\n",
    "                \n",
    "                if (org_id not in org_map or customer_id not in customer_map or \n",
    "                    org_user_id not in ou_map):\n",
    "                    print(f\"Skipping facturation {row['id']}: missing foreign keys\")\n",
    "                    continue\n",
    "                \n",
    "                facturation = Facturation(\n",
    "                    id=str(row['id']),\n",
    "                    organization_id=org_map[org_id],\n",
    "                    customer=customer_map[customer_id],\n",
    "                    custom_customer=row['custom_customer'] or None,\n",
    "                    organization_user=ou_map[org_user_id],\n",
    "                    bill_number=row['bill_number'] or f\"FACT-{row['id']}\",\n",
    "                    is_delivered=row['is_delivered'].lower() == 'true' if row.get('is_delivered') else True,\n",
    "                    is_proforma=row['is_proforma'].lower() == 'true' if row.get('is_proforma') else False,\n",
    "                    placed_at=_parse_datetime(row['placed_at']),\n",
    "                    created=_parse_datetime(row.get('created')),\n",
    "                    modified=_parse_datetime(row.get('modified'))\n",
    "                )\n",
    "                facturations_to_create.append(facturation)\n",
    "                facturation_map[str(row['id'])] = facturation\n",
    "            except Exception as e:\n",
    "                print(f\"Error importing facturation {row.get('id')}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if facturations_to_create:\n",
    "            Facturation.objects.bulk_create(facturations_to_create)\n",
    "            print(f\"Imported {len(facturations_to_create)} facturations\")\n",
    "    \n",
    "    return facturation_map\n",
    "\n",
    "def _create_stocks_from_facturation_batches(export_dir, org_map, batch_map, ou_map, target_org_id):\n",
    "    \"\"\"Create Stock records from FacturationBatch data for target organization.\"\"\"\n",
    "    filepath = os.path.join(export_dir, 'facturation_batches.csv')\n",
    "    stock_map = {}\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: Facturation batches file not found: {filepath}\")\n",
    "        return stock_map\n",
    "    \n",
    "    # First, read all facturation batches to calculate required stock quantities\n",
    "    batch_stock_required = {}\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                org_id = str(row['organization_id'])\n",
    "                \n",
    "                # Only process for target organization\n",
    "                if org_id != target_org_id:\n",
    "                    continue\n",
    "                \n",
    "                batch_id = str(row['batch_id'])\n",
    "                quantity = int(float(row['quantity'])) if row['quantity'] else 0\n",
    "                \n",
    "                if batch_id not in batch_stock_required:\n",
    "                    batch_stock_required[batch_id] = 0\n",
    "                batch_stock_required[batch_id] += quantity\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # Create Stock records\n",
    "    stocks_to_create = []\n",
    "    stock_counter = 1\n",
    "    \n",
    "    for batch_id, total_quantity in batch_stock_required.items():\n",
    "        try:\n",
    "            if batch_id not in batch_map:\n",
    "                print(f\"Skipping stock for batch {batch_id}: batch not found\")\n",
    "                continue\n",
    "            \n",
    "            batch = batch_map[batch_id]\n",
    "            org_id = batch.organization_id\n",
    "            \n",
    "            # Get a valid organization user for this stock\n",
    "            org_user = None\n",
    "            for ou in ou_map.values():\n",
    "                if ou.organization_id == org_id:\n",
    "                    org_user = ou\n",
    "                    break\n",
    "            \n",
    "            if not org_user:\n",
    "                print(f\"No organization user found for org {org_id}, skipping stock\")\n",
    "                continue\n",
    "            \n",
    "            # Create one stock record per batch with the total required quantity\n",
    "            stock = Stock(\n",
    "                id=stock_counter,\n",
    "                organization_id=org_map[org_id],\n",
    "                organization_user=org_user,\n",
    "                batch=batch,\n",
    "                quantity=total_quantity\n",
    "            )\n",
    "            stocks_to_create.append(stock)\n",
    "            stock_map[batch_id] = stock\n",
    "            stock_counter += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating stock for batch {batch_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if stocks_to_create:\n",
    "        Stock.objects.bulk_create(stocks_to_create)\n",
    "        print(f\"Created {len(stocks_to_create)} stock records\")\n",
    "    \n",
    "    return stock_map\n",
    "\n",
    "def _import_facturation_stocks(export_dir, org_map, stock_map, facturation_map, ou_map, target_org_id):\n",
    "    \"\"\"Import FacturationStock from FacturationBatch data for target organization\"\"\"\n",
    "    filepath = os.path.join(export_dir, 'facturation_batches.csv')\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: Facturation batches file not found: {filepath}\")\n",
    "        return\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        facturation_stocks_to_create = []\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                org_id = str(row['organization_id'])\n",
    "                facturation_id = str(row['facturation_id'])\n",
    "                batch_id = str(row['batch_id'])\n",
    "                org_user_id = str(row['organization_user_id'])\n",
    "                \n",
    "                # Only import for target organization\n",
    "                if org_id != target_org_id:\n",
    "                    continue\n",
    "                \n",
    "                if (facturation_id not in facturation_map or batch_id not in stock_map or\n",
    "                    org_id not in org_map or org_user_id not in ou_map):\n",
    "                    print(f\"Skipping facturation stock {row['id']}: missing foreign keys\")\n",
    "                    continue\n",
    "                \n",
    "                facturation_stock = FacturationStock(\n",
    "                    id=str(row['id']),  # Preserve original FacturationBatch ID\n",
    "                    organization_id=org_map[org_id],\n",
    "                    stock=stock_map[batch_id],\n",
    "                    organization_user=ou_map[org_user_id],\n",
    "                    facturation=facturation_map[facturation_id],\n",
    "                    unit_price=Decimal(row['unit_price']) if row['unit_price'] else Decimal('0'),\n",
    "                    quantity=int(float(row['quantity'])) if row['quantity'] else 0,\n",
    "                    is_delivered=row['is_delivered'].lower() == 'true' if row.get('is_delivered') else False,\n",
    "                    created=_parse_datetime(row.get('created')),\n",
    "                    modified=_parse_datetime(row.get('modified'))\n",
    "                )\n",
    "                facturation_stocks_to_create.append(facturation_stock)\n",
    "            except Exception as e:\n",
    "                print(f\"Error importing facturation stock {row.get('id')}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if facturation_stocks_to_create:\n",
    "            FacturationStock.objects.bulk_create(facturation_stocks_to_create)\n",
    "            print(f\"Imported {len(facturation_stocks_to_create)} facturation stocks\")\n",
    "\n",
    "def _import_transactions(export_dir, org_map, ou_map, target_org_id):\n",
    "    \"\"\"Import transactions for target organization\"\"\"\n",
    "    filepath = os.path.join(export_dir, 'transactions.csv')\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: Transactions file not found: {filepath}\")\n",
    "        return\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        transactions_to_create = []\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                org_id = str(row['organization_id'])\n",
    "                org_user_id = str(row['organization_user_id'])\n",
    "                \n",
    "                # Only import for target organization\n",
    "                if org_id != target_org_id:\n",
    "                    continue\n",
    "                \n",
    "                if org_id not in org_map or org_user_id not in ou_map:\n",
    "                    print(f\"Skipping transaction {row['id']}: missing foreign keys\")\n",
    "                    continue\n",
    "                \n",
    "                transaction = Transaction(\n",
    "                    id=str(row['id']),\n",
    "                    organization_id=org_map[org_id],\n",
    "                    organization_user=ou_map[org_user_id],\n",
    "                    transaction_broker=row['transaction_broker'],\n",
    "                    transaction_type=row['transaction_type'],\n",
    "                    amount=Decimal(row['amount']) if row['amount'] else Decimal('0'),\n",
    "                    participant=row['participant'] or '',\n",
    "                    reason=row['reason'] or '',\n",
    "                    created=_parse_datetime(row.get('created')),\n",
    "                    modified=_parse_datetime(row.get('modified'))\n",
    "                )\n",
    "                transactions_to_create.append(transaction)\n",
    "            except Exception as e:\n",
    "                print(f\"Error importing transaction {row.get('id')}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if transactions_to_create:\n",
    "            Transaction.objects.bulk_create(transactions_to_create)\n",
    "            print(f\"Imported {len(transactions_to_create)} transactions\")\n",
    "\n",
    "def _import_facturation_payments(export_dir, org_map, facturation_map, ou_map, target_org_id):\n",
    "    \"\"\"Import facturation payments for target organization\"\"\"\n",
    "    filepath = os.path.join(export_dir, 'facturation_payments.csv')\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: Facturation payments file not found: {filepath}\")\n",
    "        return\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        payments_to_create = []\n",
    "        \n",
    "        for row in reader:\n",
    "            try:\n",
    "                org_id = str(row['organization_id'])\n",
    "                facturation_id = str(row['facturation_id'])\n",
    "                org_user_id = str(row['organization_user_id'])\n",
    "                \n",
    "                # Only import for target organization\n",
    "                if org_id != target_org_id:\n",
    "                    continue\n",
    "                \n",
    "                if (org_id not in org_map or facturation_id not in facturation_map or \n",
    "                    org_user_id not in ou_map):\n",
    "                    print(f\"Skipping facturation payment {row['id']}: missing foreign keys\")\n",
    "                    continue\n",
    "                \n",
    "                payment = FacturationPayment(\n",
    "                    id=str(row['id']),\n",
    "                    organization_id=org_map[org_id],\n",
    "                    facturation=facturation_map[facturation_id],\n",
    "                    organization_user=ou_map[org_user_id],\n",
    "                    transaction_broker=row['transaction_broker'],\n",
    "                    amount=Decimal(row['amount']) if row['amount'] else Decimal('0'),\n",
    "                    created=_parse_datetime(row.get('created')),\n",
    "                    modified=_parse_datetime(row.get('modified'))\n",
    "                )\n",
    "                payments_to_create.append(payment)\n",
    "            except Exception as e:\n",
    "                print(f\"Error importing facturation payment {row.get('id')}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if payments_to_create:\n",
    "            FacturationPayment.objects.bulk_create(payments_to_create)\n",
    "            print(f\"Imported {len(payments_to_create)} facturation payments\")\n",
    "\n",
    "def _parse_datetime(value):\n",
    "    \"\"\"Parse datetime string safely\"\"\"\n",
    "    if not value:\n",
    "        return timezone.now()\n",
    "    try:\n",
    "        return timezone.datetime.fromisoformat(value.replace('Z', '+00:00'))\n",
    "    except (ValueError, AttributeError):\n",
    "        return timezone.now()\n",
    "\n",
    "def _parse_date(value):\n",
    "    \"\"\"Parse date string safely\"\"\"\n",
    "    if not value:\n",
    "        return timezone.now().date()\n",
    "    try:\n",
    "        return timezone.datetime.fromisoformat(value.replace('Z', '+00:00')).date()\n",
    "    except (ValueError, AttributeError):\n",
    "        return timezone.now().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23b0f036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data import for organization ID: 69393ba2-3fbd-4ca8-a2d8-2e75ff14093d...\n"
     ]
    }
   ],
   "source": [
    "# Then import\n",
    "import_success, import_message = import_organization_data(\n",
    "        export_dir='./demo/data',\n",
    "        target_org_id=organization_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b464b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1dec75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
